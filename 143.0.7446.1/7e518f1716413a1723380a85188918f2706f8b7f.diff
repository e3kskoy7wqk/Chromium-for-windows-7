diff --git a/media/gpu/av1_decoder.cc b/media/gpu/av1_decoder.cc
index 5c5210a4b5656..f8b20958133e0 100644
--- a/media/gpu/av1_decoder.cc
+++ b/media/gpu/av1_decoder.cc
@@ -297,9 +297,8 @@ AcceleratedVideoDecoder::DecodeResult AV1Decoder::DecodeInternal() {
           chroma_sampling_ = new_chroma_sampling;
         }
 
-        if (chroma_sampling_ != VideoChromaSampling::k420 &&
-            chroma_sampling_ != VideoChromaSampling::k444) {
-          DVLOG(1) << "Only YUV 4:2:0 and YUV 4:4:4 are supported";
+        if (chroma_sampling_ != VideoChromaSampling::k420) {
+          DVLOG(1) << "Only YUV 4:2:0 is supported";
           return kDecodeError;
         }
 
diff --git a/media/gpu/av1_decoder_unittest.cc b/media/gpu/av1_decoder_unittest.cc
index 1ea28080459ec..a8b2c7a2a1c82 100644
--- a/media/gpu/av1_decoder_unittest.cc
+++ b/media/gpu/av1_decoder_unittest.cc
@@ -60,10 +60,6 @@ bool IsYUV420(int8_t subsampling_x, int8_t subsampling_y, bool is_monochrome) {
   return subsampling_x == 1 && subsampling_y == 1 && !is_monochrome;
 }
 
-bool IsYUV444(int8_t subsampling_x, int8_t subsampling_y, bool is_monochrome) {
-  return subsampling_x == 0 && subsampling_y == 0 && !is_monochrome;
-}
-
 MATCHER_P(SameAV1PictureInstance, av1_picture, "") {
   return &arg == av1_picture.get();
 }
@@ -112,23 +108,6 @@ MATCHER_P4(MatchesYUV420SequenceHeader,
                   arg.color_config.is_monochrome);
 }
 
-MATCHER_P4(MatchesYUV444SequenceHeader,
-           profile,
-           bitdepth,
-           max_frame_size,
-           film_grain_params_present,
-           "") {
-  return arg.profile == profile && arg.color_config.bitdepth == bitdepth &&
-         base::strict_cast<int>(arg.max_frame_width) ==
-             max_frame_size.width() &&
-         base::strict_cast<int>(arg.max_frame_height) ==
-             max_frame_size.height() &&
-         arg.film_grain_params_present == film_grain_params_present &&
-         IsYUV444(arg.color_config.subsampling_x,
-                  arg.color_config.subsampling_y,
-                  arg.color_config.is_monochrome);
-}
-
 MATCHER(NonEmptyTileBuffers, "") {
   return !arg.empty();
 }
@@ -511,76 +490,15 @@ TEST_F(AV1DecoderTest, DecodeSVCStream) {
   EXPECT_EQ(Decode(buffers[1]), expected);
 }
 
-TEST_F(AV1DecoderTest, Decode8bProfile1) {
-  const std::string kYUV444Stream("bear_av1_720p_444_8bit.ivf");
+TEST_F(AV1DecoderTest, DenyDecodeNonYUV420) {
+  const std::string kYUV444Stream("blackwhite_yuv444p-frame.av1.ivf");
   std::vector<scoped_refptr<DecoderBuffer>> buffers = ReadIVF(kYUV444Stream);
-  ASSERT_EQ(buffers.size(), 2u);
-  constexpr gfx::Size kFrameSize(1280, 720);
-  constexpr gfx::Size kRenderSize(1280, 720);
-  constexpr auto kProfile = libgav1::BitstreamProfile::kProfile1;
-  std::vector<DecodeResult> expected = {DecodeResult::kConfigChange};
-  std::vector<DecodeResult> results;
-  for (auto buffer : buffers) {
-    ::testing::InSequence sequence;
-    auto av1_picture = base::MakeRefCounted<AV1Picture>();
-    EXPECT_CALL(*mock_accelerator_, CreateAV1Picture(/*apply_grain=*/false))
-        .WillOnce(Return(av1_picture));
-    EXPECT_CALL(
-        *mock_accelerator_,
-        SubmitDecode(
-            MatchesFrameHeader(kFrameSize, kRenderSize,
-                               /*show_existing_frame=*/false,
-                               /*show_frame=*/true),
-            MatchesYUV444SequenceHeader(kProfile, /*bitdepth=*/8, kFrameSize,
-                                        /*film_grain_params_present=*/false),
-            _, NonEmptyTileBuffers(), MatchesFrameData(buffer)))
-        .WillOnce(Return(AV1Decoder::AV1Accelerator::Status::kOk));
-    EXPECT_CALL(*mock_accelerator_,
-                OutputPicture(SameAV1PictureInstance(av1_picture)))
-        .WillOnce(Return(true));
-    for (DecodeResult r : Decode(buffer)) {
-      results.push_back(r);
-    }
-    expected.push_back(DecodeResult::kRanOutOfStreamData);
-    testing::Mock::VerifyAndClearExpectations(mock_accelerator_);
-  }
-  EXPECT_EQ(results, expected);
-}
-
-TEST_F(AV1DecoderTest, Decode10bProfile1) {
-  const std::string kYUV444Stream("bear_av1_720p_444_10bit.ivf");
-  std::vector<scoped_refptr<DecoderBuffer>> buffers = ReadIVF(kYUV444Stream);
-  ASSERT_EQ(buffers.size(), 2u);
-  constexpr gfx::Size kFrameSize(1280, 720);
-  constexpr gfx::Size kRenderSize(1280, 720);
-  constexpr auto kProfile = libgav1::BitstreamProfile::kProfile1;
-  std::vector<DecodeResult> expected = {DecodeResult::kConfigChange};
-  std::vector<DecodeResult> results;
-  for (auto buffer : buffers) {
-    ::testing::InSequence sequence;
-    auto av1_picture = base::MakeRefCounted<AV1Picture>();
-    EXPECT_CALL(*mock_accelerator_, CreateAV1Picture(/*apply_grain=*/false))
-        .WillOnce(Return(av1_picture));
-    EXPECT_CALL(
-        *mock_accelerator_,
-        SubmitDecode(
-            MatchesFrameHeader(kFrameSize, kRenderSize,
-                               /*show_existing_frame=*/false,
-                               /*show_frame=*/true),
-            MatchesYUV444SequenceHeader(kProfile, /*bitdepth=*/10, kFrameSize,
-                                        /*film_grain_params_present=*/false),
-            _, NonEmptyTileBuffers(), MatchesFrameData(buffer)))
-        .WillOnce(Return(AV1Decoder::AV1Accelerator::Status::kOk));
-    EXPECT_CALL(*mock_accelerator_,
-                OutputPicture(SameAV1PictureInstance(av1_picture)))
-        .WillOnce(Return(true));
-    for (DecodeResult r : Decode(buffer)) {
-      results.push_back(r);
-    }
-    expected.push_back(DecodeResult::kRanOutOfStreamData);
-    testing::Mock::VerifyAndClearExpectations(mock_accelerator_);
-  }
-  EXPECT_EQ(results, expected);
+  ASSERT_EQ(buffers.size(), 1u);
+  std::vector<DecodeResult> expected = {DecodeResult::kDecodeError};
+  EXPECT_EQ(Decode(buffers[0]), expected);
+  // Once AV1Decoder gets into an error state, Decode() returns kDecodeError
+  // until Reset().
+  EXPECT_EQ(Decode(buffers[0]), expected);
 }
 
 TEST_F(AV1DecoderTest, DecodeFilmGrain) {
diff --git a/media/gpu/windows/d3d11_decoder_configurator.cc b/media/gpu/windows/d3d11_decoder_configurator.cc
index 5e410bbf733c3..667631b55e7aa 100644
--- a/media/gpu/windows/d3d11_decoder_configurator.cc
+++ b/media/gpu/windows/d3d11_decoder_configurator.cc
@@ -126,14 +126,6 @@ std::unique_ptr<D3D11DecoderConfigurator> D3D11DecoderConfigurator::Create(
     }
   }
 #endif  // BUILDFLAG(ENABLE_HEVC_PARSER_AND_HW_DECODER)
-  if (decoder_guid == DXVA_ModeAV1_VLD_Profile1) {
-    // AV1 profile 1 is YUV 4:4:4 only.
-    if (bit_depth == 8) {
-      decoder_dxgi_format = DXGI_FORMAT_AYUV;
-    } else if (bit_depth == 10) {
-      decoder_dxgi_format = DXGI_FORMAT_Y410;
-    }
-  }
   if (decoder_guid == GUID()) {
     if (config.profile() == HEVCPROFILE_REXT) {
       MEDIA_LOG(INFO, media_log)
diff --git a/media/gpu/windows/d3d12_video_decoder_wrapper.cc b/media/gpu/windows/d3d12_video_decoder_wrapper.cc
index fbbac61f12800..d8c2294669740 100644
--- a/media/gpu/windows/d3d12_video_decoder_wrapper.cc
+++ b/media/gpu/windows/d3d12_video_decoder_wrapper.cc
@@ -385,15 +385,6 @@ std::unique_ptr<D3D12VideoDecoderWrapper> D3D12VideoDecoderWrapper::Create(
   }
 #endif  // BUILDFLAG(ENABLE_HEVC_PARSER_AND_HW_DECODER)
 
-  if (guid == DXVA_ModeAV1_VLD_Profile1) {
-    // AV1 profile 1 is YUV 4:4:4 only.
-    if (bit_depth == 8) {
-      decode_format = DXGI_FORMAT_AYUV;
-    } else if (bit_depth == 10) {
-      decode_format = DXGI_FORMAT_Y410;
-    }
-  }
-
   D3D12_FEATURE_DATA_VIDEO_DECODE_SUPPORT feature{
       .Configuration = {guid},
       .Width = static_cast<UINT>(config.coded_size().width()),
diff --git a/media/test/data/README.md b/media/test/data/README.md
index 66b7b1aa1067e..8298cf8fe02a5 100644
--- a/media/test/data/README.md
+++ b/media/test/data/README.md
@@ -413,16 +413,6 @@ AV1 data where film grain feature is used.
 This is the same as av1-1-b8-23-film\_grain-50.ivf in [libaom test vectors].
 The video license is [libaom LICENSE].
 
-#### bear_av1_720p_444_8bit.ivf
-AV1 high profile 8-bit stream containing two frames, created by the following command.
-`ffmpeg -i bear-1280x720.mp4 -frames:v 2 -c:v libaom-av1 -pix_fmt yuv444p \
--crf 30 -b:v 0 -strict experimental -cpu-used 4 -profile:v 1 bear_av1_720p_444_8bit.ivf`
-
-#### bear_av1_720p_444_10bit.ivf
-AV1 high profile 10-bit stream containing two frames, created by the following command.
-`ffmpeg -i bear-1280x720.mp4 -frames:v 2 -c:v libaom-av1 -pix_fmt yuv444p10le \
--crf 30 -b:v 0 -strict experimental -cpu-used 4 -profile:v 1 bear_av1_720p_444_10bit.ivf`
-
 ### Alpha Channel
 
 #### bear-vp8a.webm
diff --git a/media/test/media_bundle_data.filelist b/media/test/media_bundle_data.filelist
index b1231afbd4d4e..7f76509e4e7b8 100644
--- a/media/test/media_bundle_data.filelist
+++ b/media/test/media_bundle_data.filelist
@@ -272,8 +272,6 @@ data/bear_audio_longer_than_video.ogv
 data/bear_audio_longer_than_video_vp8.ogv
 data/bear_audio_shorter_than_video.ogv
 data/bear_audio_shorter_than_video_vp8.ogv
-data/bear_av1_720p_444_10bit.ivf
-data/bear_av1_720p_444_8bit.ivf
 data/bear_dtsc.mp4
 data/bear_dtse.mp4
 data/bear_dtsx.mp4
diff --git a/media/unit_tests_bundle_data.filelist b/media/unit_tests_bundle_data.filelist
index 061b6ce98bf13..a4d5ba5c02d08 100644
--- a/media/unit_tests_bundle_data.filelist
+++ b/media/unit_tests_bundle_data.filelist
@@ -284,8 +284,6 @@
 //media/test/data/bear_audio_longer_than_video_vp8.ogv
 //media/test/data/bear_audio_shorter_than_video.ogv
 //media/test/data/bear_audio_shorter_than_video_vp8.ogv
-//media/test/data/bear_av1_720p_444_10bit.ivf
-//media/test/data/bear_av1_720p_444_8bit.ivf
 //media/test/data/bear_dtsc.mp4
 //media/test/data/bear_dtse.mp4
 //media/test/data/bear_dtsx.mp4
